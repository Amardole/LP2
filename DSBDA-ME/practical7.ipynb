{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e57e963-9d99-4609-b46b-16de62124222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\amard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download required NLTK packages (run only once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57518dea-48a6-42d2-ac18-e4cb938db929",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural Language Processing is a powerful tool in data science. It helps machines understand human language.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48846aae-fd2f-4db6-8935-0e54e67f543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', 'is', 'a', 'powerful', 'tool', 'in', 'data', 'science', '.', 'It', 'helps', 'machines', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77153b32-63e2-4d72-b6a5-dbcf1890d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('tool', 'NN'), ('in', 'IN'), ('data', 'NNS'), ('science', 'NN'), ('.', '.'), ('It', 'PRP'), ('helps', 'VBZ'), ('machines', 'NNS'), ('understand', 'JJ'), ('human', 'JJ'), ('language', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = pos_tag(tokens)\n",
    "print(\"POS Tags:\", pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d18de2-7432-4ac1-9b01-78ba8908ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stop Words Removal: ['Natural', 'Language', 'Processing', 'powerful', 'tool', 'data', 'science', '.', 'helps', 'machines', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"After Stop Words Removal:\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40311b0-cb59-4a31-9659-56fc7b073ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming: ['natur', 'languag', 'process', 'power', 'tool', 'data', 'scienc', '.', 'help', 'machin', 'understand', 'human', 'languag', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(\"After Stemming:\", stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c35c31d-ea43-453b-aa0a-24deaabee161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization: ['Natural', 'Language', 'Processing', 'powerful', 'tool', 'data', 'science', '.', 'help', 'machine', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"After Lemmatization:\", lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265dbc00-9eae-4cb7-8d77-a1dd8734a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and       can      data  documents      help     human       idf  \\\n",
      "0  0.000000  0.000000  0.341426   0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.389888  0.000000   0.000000  0.000000  0.389888  0.000000   \n",
      "2  0.353553  0.000000  0.000000   0.353553  0.353553  0.000000  0.353553   \n",
      "\n",
      "         in        is  language  ...       nlp  numerically  powerful  \\\n",
      "0  0.341426  0.341426  0.259663  ...  0.000000     0.000000  0.341426   \n",
      "1  0.000000  0.000000  0.296520  ...  0.389888     0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  ...  0.000000     0.353553  0.000000   \n",
      "\n",
      "   processing  represent   science        tf   through        to      tool  \n",
      "0    0.341426   0.000000  0.341426  0.000000  0.000000  0.000000  0.341426  \n",
      "1    0.000000   0.000000  0.000000  0.000000  0.389888  0.000000  0.000000  \n",
      "2    0.000000   0.353553  0.000000  0.353553  0.000000  0.353553  0.000000  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's say we have multiple documents\n",
    "documents = [\n",
    "    \"Natural Language Processing is a powerful tool in data science.\",\n",
    "    \"Machines can learn human language through NLP.\",\n",
    "    \"TF and IDF help to represent documents numerically.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# View as DataFrame for better readability\n",
    "import pandas as pd\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea47ea6-d847-4318-a765-675f5e0efb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
